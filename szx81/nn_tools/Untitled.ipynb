{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float_kind':\"{:-.3e}\".format})\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import core as co\n",
    "import hist_data as hd\n",
    "hd.set_hist_data(data_count=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataSource:\n",
    "    def __init__(self, data, scalers, step=1):\n",
    "        \n",
    "        self.data = list(data)\n",
    "        self.step = step\n",
    "        self.scalers = scalers\n",
    "        self.feature_count = 2\n",
    "        self.end_index = None\n",
    "        self.data_count = None\n",
    "        self.features = None\n",
    "        self.targets = None\n",
    "        self.indexes = None\n",
    " \n",
    "        self.fit_data()\n",
    "\n",
    "    def fit_data(self):\n",
    "        return\n",
    "        # opens = []\n",
    "        # volumes = []\n",
    "\n",
    "        # for i in range(0, len(self.data)):  \n",
    "        #     open = 0\n",
    "        #     volume = 0\n",
    "        #     if not i + step < len(self.data):\n",
    "        #         break\n",
    "        #     for k in range(step):\n",
    "        #         val = self.data[i + k]\n",
    "        #         open += (val[1][0][0] + val[1][1][0]) / 2\n",
    "        #         volume += val[2]              \n",
    "\n",
    "        #     opens.append(open / self.step) #.reshape(-1, 1)\n",
    "        #     volumes.append(volume / self.step) #.reshape(-1, 1)\n",
    "\n",
    "        # opens = np.array(opens).reshape(-1, 1)\n",
    "        # volumes = np.log(np.array(volumes).reshape(-1, 1) + 10.0)\n",
    "\n",
    "        # self.fit_transform([opens, volumes])\n",
    "\n",
    "    def feature_names(self):\n",
    "        return [str(i) for i in range(20)]\n",
    "        # Change accordingly\n",
    "    \n",
    "    def target_names(self):\n",
    "        return [str(i) for i in range(20)]\n",
    "        # Change accordingly   \n",
    "\n",
    "    def fit(self, data):\n",
    "        for i in range(len(data)):\n",
    "            if data[i] is not None:\n",
    "                data[i] = self.scalers[i].fit(data[i])\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        for i in range(len(data)):\n",
    "            if data[i] is not None:\n",
    "                data[i] = self.scalers[i].fit_transform(data[i])\n",
    "        return data\n",
    "    \n",
    "    def transform(self, data, index=None):\n",
    "        if index is None:\n",
    "            for i in range(len(data)):\n",
    "                if data[i] is not None:\n",
    "                    data[i] = self.scalers[i].transform(data[i])\n",
    "        else:\n",
    "            data = self.scalers[index].transform(data)\n",
    "        return data\n",
    "    \n",
    "    def inverse_transform(self, data, index=None):\n",
    "        if index is None:\n",
    "            for i in range(len(data)):\n",
    "                if data[i] is not None:\n",
    "                    data[i] = self.scalers[i].inverse_x(data[i])\n",
    "        else:\n",
    "            data = self.scalers[index].inverse_x(data)        \n",
    "        return data\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.indexes)\n",
    "    \n",
    "    def get_data__(self):\n",
    "        # Change accordingly   \n",
    "        return (\n",
    "            self.features, \n",
    "            self.targets, \n",
    "            self.indexes)\n",
    "    \n",
    "    def get_data(self, end_index, data_count, future_count):\n",
    "        \"\"\"\n",
    "        Returns amount of data, typically called by a ``Context Sequencer`` \n",
    "        or ``Predictor``.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        end_index : Index of oldest historical data used, including targeting.\n",
    "        data_count : Index of the earliest historical data used is \n",
    "            `end_index - data_count` (possibly lowered in order to meet \n",
    "            constrictions.)\n",
    "        future_count : Historical data index difference between training\n",
    "            and prediction data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "\n",
    "        (features, targets, indexes) : Tuple of numpy arrays containing\n",
    "            data relevant (yet not formatted) for nn modeling.\n",
    "        \"\"\"\n",
    "        self.end_index = end_index\n",
    "        self.data_count = data_count\n",
    "        self.feature_count = future_count\n",
    "\n",
    "        feature_data_count = self.data_count - self.future_count\n",
    "\n",
    "        if feature_data_count % self.step != 0:\n",
    "            feature_data_count = (feature_data_count // self.step + 1) \\\n",
    "                * self.step\n",
    "        begin = self.end_index - feature_data_count - future_count\n",
    "        if begin + 1 < 0 or self.end_index + 1 > len(self.data):\n",
    "            raise Exception(f'''\n",
    "ERROR\n",
    "The wanted data range is \n",
    "({begin + 1}, {self.end_index + 1})\n",
    "while the maximal is\n",
    "({0}, {len(self.data)})\n",
    "''')\n",
    "\n",
    "        return self.get_data__(\n",
    "            end_index, data_count, future_count)\n",
    "        \n",
    "    def report(self, verbose=False):\n",
    "        index_count = self.indexes[-1] - self.indexes[0]\n",
    "        print(f'''\n",
    "wanted end index: ({self.end_index})\n",
    "wanted data count {self.data_count}\n",
    "index range: ({self.indexes[0]}, {self.indexes[-1]})\n",
    "index count: {self.indexes[-1] - self.indexes[0]}''')\n",
    "        if index_count != self.data_count:\n",
    "            print('Real data count is adjusted to constrictions.')\n",
    "        else:\n",
    "            print()\n",
    "        if verbose:\n",
    "            print(f'''\n",
    "features:\n",
    "{self.features[:3]}\n",
    "targets:\n",
    "{self.targets[:3]}\n",
    "indexes:\n",
    "{self.indexes[:3]}\n",
    "''')\n",
    "\n",
    "    def plot(self):\n",
    "        targets = self.targets.transpose()\n",
    "        for i in range(len(targets)):\n",
    "            plt.plot(self.indexes, targets[i], label=self.target_names()[i])\n",
    "        features = self.features.transpose()\n",
    "        for i in range(len(features)):\n",
    "            plt.plot(self.indexes, features[i], label=self.feature_names()[i])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class ForexDataSource(DataSource):\n",
    "    def fit_data(self):\n",
    "        opens = []\n",
    "        volumes = []\n",
    "\n",
    "        for i in range(0, len(self.data)):  \n",
    "            open = 0\n",
    "            volume = 0\n",
    "            if not i + self.step < len(self.data):\n",
    "                break\n",
    "            for k in range(self.step):\n",
    "                val = self.data[i + k]\n",
    "                open += (val[1][0][0] + val[1][1][0]) / 2\n",
    "                volume += val[2]              \n",
    "\n",
    "            opens.append(open / self.step) #.reshape(-1, 1)\n",
    "            volumes.append(volume / self.step) #.reshape(-1, 1)\n",
    "\n",
    "        opens = np.array(opens).reshape(-1, 1)\n",
    "        volumes = np.log(np.array(volumes).reshape(-1, 1) + 10.0)\n",
    "\n",
    "        self.fit_transform([opens, volumes])\n",
    "\n",
    "    def feature_names(self):\n",
    "        return ('opens', 'volumes')\n",
    "    \n",
    "    def target_names(self):\n",
    "        return ('opens target',)\n",
    "        \n",
    "    def get_data__(self):\n",
    "        def helper(i):\n",
    "            val = self.data[i]\n",
    "            return (val[1][0][0] + val[1][1][0]) / 2, val[2]\n",
    "\n",
    "        indexes = [] \n",
    "        opens = []\n",
    "        volumes = []\n",
    "        targets = []\n",
    "        for i in range(self.begin, self.end_index, self.step):\n",
    "            index = 0\n",
    "            open = 0\n",
    "            volume = 0\n",
    "            target = 0\n",
    "            index = i + self.step - 1\n",
    "            for k in range(self.step):\n",
    "                _open, _volume = helper(i + k)\n",
    "                open += _open\n",
    "                volume += _volume\n",
    "                _open, _volume = helper(i + k + self.future_count)\n",
    "                target += _open\n",
    "\n",
    "            indexes.append(index)\n",
    "            opens.append(open / self.step)\n",
    "            volumes.append(volume / self.step)\n",
    "            targets.append(target / self.step)\n",
    "\n",
    "        opens = np.array(opens).reshape(-1, 1)\n",
    "        volumes = np.log(np.array(volumes).reshape(-1, 1) + 10.0)\n",
    "        opens, volumes = self.transform([opens, volumes])\n",
    "\n",
    "        targets = np.array(targets).reshape(-1, 1)\n",
    "        targets = self.transform(targets, index=0)\n",
    "\n",
    "        self.features = np.concatenate((opens, volumes), axis=1)\n",
    "        self.targets = targets\n",
    "        self.indexes = np.array(indexes).reshape(-1, 1)\n",
    "        return (\n",
    "            self.features, \n",
    "            self.targets, \n",
    "            self.indexes)\n",
    "\n",
    "#     def get_data(self, end_index, data_count, future_count):\n",
    "#         \"\"\"\n",
    "#         Returns amount of data, typically called by a ``Context Sequencer`` \n",
    "#         or ``Predictor``.\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         end_index : Index of oldest historical data used, including targeting.\n",
    "#         data_count : Index of the earliest historical data used is \n",
    "#             `end_index - data_count` (possibly lowered in order to meet \n",
    "#             constrictions.)\n",
    "#         future_count : Historical data index difference between training\n",
    "#             and prediction data\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "\n",
    "#         (features, targets, indexes) : Tuple of numpy arrays containing\n",
    "#             data relevant (yet not formatted) for nn modeling.\n",
    "#         \"\"\"\n",
    "#         self.end_index = end_index\n",
    "#         self.data_count = data_count\n",
    "\n",
    "#         feature_data_count = self.data_count - future_count\n",
    "\n",
    "#         if feature_data_count % self.step != 0:\n",
    "#             feature_data_count = (feature_data_count // self.step + 1) \\\n",
    "#                 * self.step\n",
    "#         begin = self.end_index - feature_data_count - future_count\n",
    "#         if begin + 1 < 0 or self.end_index + 1 > len(self.data):\n",
    "#             raise Exception(f'''\n",
    "# ERROR\n",
    "# The wanted data range is \n",
    "# ({begin + 1}, {self.end_index + 1})\n",
    "# while the maximal is\n",
    "# ({0}, {len(self.data)})\n",
    "# ''')\n",
    "        \n",
    "\n",
    "\n",
    "#         def helper(i):\n",
    "#             val = self.data[i]\n",
    "#             return (val[1][0][0] + val[1][1][0]) / 2, val[2]\n",
    "\n",
    "#         indexes = [] \n",
    "#         opens = []\n",
    "#         volumes = []\n",
    "#         targets = []\n",
    "#         for i in range(begin, self.end_index, self.step):\n",
    "#             index = 0\n",
    "#             open = 0\n",
    "#             volume = 0\n",
    "#             target = 0\n",
    "#             index = i + self.step - 1\n",
    "#             for k in range(self.step):\n",
    "#                 _open, _volume = helper(i + k)\n",
    "#                 open += _open\n",
    "#                 volume += _volume\n",
    "#                 _open, _volume = helper(i + k + future_count)\n",
    "#                 target += _open\n",
    "\n",
    "#             indexes.append(index)\n",
    "#             opens.append(open / self.step)\n",
    "#             volumes.append(volume / self.step)\n",
    "#             targets.append(target / self.step)\n",
    "\n",
    "#         opens = np.array(opens).reshape(-1, 1)\n",
    "#         volumes = np.log(np.array(volumes).reshape(-1, 1) + 10.0)\n",
    "#         opens, volumes = self.transform([opens, volumes])\n",
    "\n",
    "#         targets = np.array(targets).reshape(-1, 1)\n",
    "#         targets = self.transform(targets, index=0)\n",
    "\n",
    "#         self.features = np.concatenate((opens, volumes), axis=1)\n",
    "#         self.targets = targets\n",
    "#         self.indexes = np.array(indexes).reshape(-1, 1)\n",
    "\n",
    "\n",
    "#         return (\n",
    "#             self.features, \n",
    "#             self.targets, \n",
    "#             self.indexes\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ForexDataSource' object has no attribute 'future_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[361], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ds = ForexDataSource(\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     hd.DICT_DATA.values(), (StandardScaler(), StandardScaler()), 3)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ds \u001b[38;5;241m=\u001b[39m ForexDataSource(\n\u001b[0;32m      5\u001b[0m     hd\u001b[38;5;241m.\u001b[39mDICT_DATA\u001b[38;5;241m.\u001b[39mvalues(), (MinMaxScaler(), MinMaxScaler()), \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m features, targets, indexes \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m98\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m ds\u001b[38;5;241m.\u001b[39mreport()\n\u001b[0;32m     10\u001b[0m ds\u001b[38;5;241m.\u001b[39mplot()\n",
      "Cell \u001b[1;32mIn[360], line 111\u001b[0m, in \u001b[0;36mDataSource.get_data\u001b[1;34m(self, end_index, data_count, future_count)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_count \u001b[38;5;241m=\u001b[39m data_count\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count \u001b[38;5;241m=\u001b[39m future_count\n\u001b[1;32m--> 111\u001b[0m feature_data_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture_count\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_data_count \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    114\u001b[0m     feature_data_count \u001b[38;5;241m=\u001b[39m (feature_data_count \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \\\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ForexDataSource' object has no attribute 'future_count'"
     ]
    }
   ],
   "source": [
    "# ds = ForexDataSource(\n",
    "#     hd.DICT_DATA.values(), (StandardScaler(), StandardScaler()), 3)\n",
    "\n",
    "ds = ForexDataSource(\n",
    "    hd.DICT_DATA.values(), (MinMaxScaler(), MinMaxScaler()), 3)\n",
    "\n",
    "features, targets, indexes = ds.get_data(\n",
    "    end_index=4000, data_count=98, future_count=10)\n",
    "ds.report()\n",
    "ds.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wanted end range: (1000)\n",
      "index range: ([3904], [4000])\n",
      "targets.shape: (33, 1)\n",
      "indexes.shape: (33, 1)\n",
      "features.shape: (33, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "wanted end range: ({1000})\n",
    "index range: ({indexes[0]}, {indexes[-1]})\n",
    "targets.shape: {targets.shape}\n",
    "indexes.shape: {indexes.shape}\n",
    "features.shape: {features.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextSequencer:\n",
    "    def __init__(self, \n",
    "                data_source, \n",
    "                seq_len=5,  \n",
    "                future_len=5, \n",
    "                end_day=0):\n",
    "        self.data_source = data_source\n",
    "        self.seq_len = seq_len\n",
    "        self.future_len = future_len\n",
    "        self.first_trained_index = end_day * co.config.PERIOD * 60 * 24\n",
    "        self.trained_indexes = set()\n",
    "        self.last_trained_index = None\n",
    "\n",
    "    def create_sequences(self, end_index, seq_len, data_count):\n",
    "        \"\"\"Lists sequences of ``data`` items, ``seq_len`` long, ``data_count`` \n",
    "        of them, ending - not including - ``end_index`` index of ``data``. Each next sequence is shifted by 1 from the previous.\n",
    "        \"\"\"        \n",
    "\n",
    "        step = self.data_source.step\n",
    "        _features, _targets, _indexes = self.data_source.get_data(\n",
    "                            end_index, \n",
    "                            data_count + seq_len * step + self.future_len)\n",
    "        features = []\n",
    "        targets = []\n",
    "        indexes = []\n",
    "        for i in range(data_count):\n",
    "            features.append(\n",
    "                _features[i: (i + seq_len)].flatten()\n",
    "            )\n",
    "            indexes.append(\n",
    "                _indexes[i + seq_len + self.future_len - 1]\n",
    "            )\n",
    "            targets.append(\n",
    "                _targets[i + seq_len + self.future_len - 1]\n",
    "            )\n",
    "\n",
    "        features = np.array(features)\n",
    "        targets = np.array(targets)\n",
    "        indexes = np.array(indexes) \n",
    "\n",
    "        return (\n",
    "            features[~np.isnan(features)], \n",
    "            targets[~np.isnan(targets)], \n",
    "            indexes[~np.isnan(indexes)]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[213], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m cs \u001b[38;5;241m=\u001b[39m ContextSequencer(\n\u001b[0;32m      2\u001b[0m     ForexDataSource(\n\u001b[0;32m      3\u001b[0m         hd\u001b[38;5;241m.\u001b[39mDICT_DATA\u001b[38;5;241m.\u001b[39mvalues(), \n\u001b[0;32m      4\u001b[0m         (StandardScaler(), StandardScaler()),\n\u001b[0;32m      5\u001b[0m         step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m         ))\n\u001b[1;32m----> 8\u001b[0m features, targets, indexes \u001b[38;5;241m=\u001b[39m \u001b[43mcs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(features[:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(targets[:10])\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(indexes[:10])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[212], line 31\u001b[0m, in \u001b[0;36mContextSequencer.create_sequences\u001b[1;34m(self, end_index, seq_len, data_count)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data_count):\n\u001b[0;32m     27\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     28\u001b[0m         _features[i: (i \u001b[38;5;241m+\u001b[39m seq_len)]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     29\u001b[0m     )\n\u001b[0;32m     30\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m---> 31\u001b[0m         \u001b[43m_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     33\u001b[0m     targets\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     34\u001b[0m         _targets[i \u001b[38;5;241m+\u001b[39m seq_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     35\u001b[0m     )\n\u001b[0;32m     37\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "cs = ContextSequencer(\n",
    "    ForexDataSource(\n",
    "        hd.DICT_DATA.values(), \n",
    "        (StandardScaler(), StandardScaler()),\n",
    "        step = 1\n",
    "        ))\n",
    "\n",
    "features, targets, indexes = cs.create_sequences(end_index=1000, seq_len=3, data_count=3000)\n",
    "print(features[:10])\n",
    "# print(targets[:10])\n",
    "# print(indexes[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Torch-Linguist](https://github.com/Ebimsv/Torch-Linguist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cpu\n",
      "0.18.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchtext\n",
    "print(torchtext.__version__)\n",
    "# ``torchtext`` is incompatible with ``torch 2.5.0``\n",
    "# Now, I have installed ``torch 2.3.0`` which is incompatible \n",
    "# with existing ``torchaudio`` and ``torchvision``\n",
    "\n",
    "# import torchaudio\n",
    "# print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python310\\lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
    "tokens\n",
    "# ['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def build_and_save_vocabulary(train_iter, vocab_path='vocab.pt', min_freq=4):\n",
    "    \"\"\"\n",
    "    Build a vocabulary from the training data iterator and save it to a file.\n",
    "    \n",
    "    Args:\n",
    "        train_iter (iterator): An iterator over the training data.\n",
    "        vocab_path (str, optional): The path to save the vocabulary file. Defaults to 'vocab.pt'.\n",
    "        min_freq (int, optional): The minimum frequency of a word to be included in the vocabulary. Defaults to 4.\n",
    "    \n",
    "    Returns:\n",
    "        torchtext.vocab.Vocab: The built vocabulary.\n",
    "    \"\"\"\n",
    "    # Get the tokenizer\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    \n",
    "    # Build the vocabulary\n",
    "    vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'], min_freq=min_freq)\n",
    "    \n",
    "    # Set the default index to the unknown token\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "    \n",
    "    # Save the vocabulary\n",
    "    torch.save(vocab, vocab_path)\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\users\\\\stefa\\\\documents\\\\workspaces\\\\szx81\\\\szx81\\\\../WikiText2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import core as co\n",
    "co.set_test_data_dir('WikiText2')\n",
    "co.TEST_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yourfile.txt', 'r') as file:\n",
    "    for line in iter(file.readline, ''):\n",
    "        print(line.strip())\n",
    "\n",
    "class TrainIter:\n",
    "    def __init__(self, data_file):\n",
    "        self.tokens = []\n",
    "        self.data_file = data_file\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.file = open(self.data_file, 'r')\n",
    "        return self\n",
    "\n",
    "    def __next__(self): # Python 2: def next(self)\n",
    "        if len(self.tokens) == 0:\n",
    "            line = iter(self.file.readline, '')\n",
    "            if line == '':\n",
    "                raise StopIteration\n",
    "            self.tokens = line.split()\n",
    "\n",
    "        return self.tokens.pop(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming you have a training data iterator named `train_iter`\n"
     ]
    }
   ],
   "source": [
    "line = 'Assuming you have a training data iterator named `train_iter`'\n",
    "print(line)\n",
    "tokens = line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "print(tokens.pop(0))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a training data iterator named `train_iter`\n",
    "\n",
    "\n",
    "vocab = build_and_save_vocabulary(train_iter, vocab_path='my_vocab.pt')\n",
    "\n",
    "# You can now use the vocabulary\n",
    "print(len(vocab))  # 23652\n",
    "print(vocab(['ebi', 'AI'.lower(), 'qwerty']))  # [0, 1973, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
